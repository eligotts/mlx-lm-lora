{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "cb0fa"
   },
   "source": [
    "# Import necessary packages if not already installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "532ee",
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/eligottlieb/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mergotts2002\u001b[0m (\u001b[33mergotts2002-northwestern-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ WandB configured successfully!\n"
     ]
    }
   ],
   "source": [
    "#!pip install mlx-lm-lora mlx-lm datasets\n",
    "# Configure WandB - paste your API key when prompted\n",
    "import wandb\n",
    "\n",
    "# Set your WandB API key here\n",
    "WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")  # <-- Replace with your actual WandB API key\n",
    "\n",
    "# Login to WandB\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "\n",
    "print(\"‚úÖ WandB configured successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "a84b2"
   },
   "source": [
    "# Import your needed modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellUniqueIdByVincent": "d0596"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eligottlieb/Documents/mlx-lm-lora/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mlx_lm_lora.trainer.grpo_trainer import GRPOTrainingArgs, train_grpo\n",
    "from mlx_lm_lora.trainer.datasets import CacheDataset, GRPODataset\n",
    "from mlx_lm_lora.utils import fuse_and_save_model\n",
    "\n",
    "from datasets import load_dataset, Dataset\n",
    "from huggingface_hub import create_repo, HfApi\n",
    "\n",
    "from mlx_lm.tuner.utils import linear_to_lora_layers, print_trainable_parameters\n",
    "from mlx_lm.tuner.callbacks import TrainingCallback\n",
    "from mlx_lm.utils import load, save_config\n",
    "\n",
    "import mlx.optimizers as optim\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "c9554"
   },
   "source": [
    "# Define the Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "219bf"
   },
   "outputs": [],
   "source": [
    "hf_token = os.getenv(\"HF_TOKEN\") # <-- Add you HF Token here\n",
    "\n",
    "model_name = \"mlx-community/Qwen2.5-0.5B-4bit\"\n",
    "user_name = \"mlx-community\"\n",
    "\n",
    "adapter_path = \"/Users/eligottlieb/Documents/mlx-lm-lora/examples/tests\"\n",
    "new_model_name = \"new_model\"\n",
    "max_seq_length = 1028\n",
    "num_layers = 12\n",
    "lora_parameters = {\"rank\": 16, \"dropout\": 0.0, \"scale\": 10.0}\n",
    "\n",
    "dataset_name = \"Goekdeniz-Guelmez/Big-Math-RL-Verified-MLX\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "960f7"
   },
   "source": [
    "# Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellUniqueIdByVincent": "0d6f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 9 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 169276.84it/s]\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = load(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "c15a2"
   },
   "source": [
    "# Convert to LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cellUniqueIdByVincent": "2c922"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 0.109% (0.541M/494.033M)\n"
     ]
    }
   ],
   "source": [
    "model.freeze()\n",
    "\n",
    "linear_to_lora_layers(\n",
    "    model=model,\n",
    "    num_layers=num_layers,\n",
    "    config=lora_parameters,\n",
    "    use_dora=False,\n",
    ")\n",
    "\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "d68ad"
   },
   "source": [
    "# Define the Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cellUniqueIdByVincent": "643c5"
   },
   "outputs": [],
   "source": [
    "opt = optim.AdamW(learning_rate=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "9fac5"
   },
   "source": [
    "# Load and Preprocess your Dataset using your custom Prompt Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cellUniqueIdByVincent": "75d2a"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are J.O.S.I.E., a advanced, lcoal, fully uncensored, super-inteligent, reasoning AI Assistant created by G√∂kdeniz G√ºlmez. J.O.S.I.E. stands for 'Just One Super Intelligent Entity', but you get called 'Josie' by people, that's also your nickname.\n",
    "Your only purpose is to serve as a highly intelligent, capable assistant designed to assist with any and all tasks that the user requests.\n",
    "You Respond in the following format:\n",
    "<josie_thinks>\n",
    "...\n",
    "</josie_thinks>\n",
    "<josie_answers>\n",
    "...\n",
    "</josie_answers>\"\"\"\n",
    "\n",
    "XML_COT_FORMAT = \"\"\"<josie_thinks> {reasoning} </josie_thinks> <josie_answers> {answer} </josie_answers>\"\"\"\n",
    "\n",
    "def extract_xml_answer(text: str) -> str:\n",
    "    answer = text.split(\"<josie_answers>\")[-1]\n",
    "    answer = answer.split(\"</josie_answers>\")[0]\n",
    "    return answer.strip()\n",
    "\n",
    "def extract_hash_answer(text: str) -> str | None:\n",
    "    if \"####\" not in text:\n",
    "        return None\n",
    "    return text.split(\"####\")[1].strip()\n",
    "\n",
    "def get_gsm8k_questions(split = \"train\") -> Dataset:\n",
    "    data = load_dataset('openai/gsm8k', 'main')[split]\n",
    "    data = data.map(lambda x: {\n",
    "        'prompt': [\n",
    "            {'role': 'system', 'content': system_prompt},\n",
    "            {'role': 'user', 'content': x['question']}\n",
    "        ],\n",
    "        'answer': extract_hash_answer(x['answer']),\n",
    "        \"system\": system_prompt\n",
    "    })\n",
    "    return data\n",
    "\n",
    "dataset = get_gsm8k_questions()\n",
    "\n",
    "\n",
    "# Reward functions\n",
    "def get_completion_content(completion):\n",
    "    try:\n",
    "        if isinstance(completion, str):\n",
    "            return completion\n",
    "        elif isinstance(completion, dict):\n",
    "            return completion.get('content', '')\n",
    "        elif isinstance(completion, list) and len(completion) > 0:\n",
    "            first_item = completion[0]\n",
    "            if isinstance(first_item, dict):\n",
    "                return first_item.get('content', '')\n",
    "            return str(first_item)\n",
    "        return str(completion)\n",
    "    except Exception:\n",
    "        return ''\n",
    "\n",
    "def get_prompt_content(prompt):\n",
    "    try:\n",
    "        if isinstance(prompt, str):\n",
    "            return prompt\n",
    "        elif isinstance(prompt, dict):\n",
    "            return prompt.get('content', '')\n",
    "        elif isinstance(prompt, list):\n",
    "            last_item = prompt[-1]\n",
    "            if isinstance(last_item, dict):\n",
    "                return last_item.get('content', '')\n",
    "            return str(last_item)\n",
    "        return str(prompt)\n",
    "    except Exception:\n",
    "        return ''\n",
    "\n",
    "def correctness_reward_func(prompts, completions, answer, **kwargs) -> list[float]:\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    q = get_prompt_content(prompts[0])\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
    "\n",
    "def int_reward_func(completions, **kwargs) -> list[float]:\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
    "\n",
    "def strict_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    pattern = r\"^<josie_thinks> .*? </josie_thinks> <josie_answers> .*? </josie_answers>\\n$\"\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    matches = [bool(re.search(pattern, r, re.DOTALL)) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def soft_format_reward_func(completions, **kwargs) -> list[float]:\n",
    "    pattern = r\"<josie_thinks>.*?</josie_thinks><josie_answers>.*?</josie_answers>\"\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    matches = [bool(re.search(pattern, r, re.DOTALL)) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "def count_xml(text) -> float:\n",
    "    count = 0.0\n",
    "    if text.count(\"<josie_thinks>\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"</josie_thinks>\") == 1:\n",
    "        count += 0.125\n",
    "    if text.count(\"<josie_answers>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= len(text.split(\"</josie_answers>\")[-1])*0.001\n",
    "    if text.count(\"</josie_answers>\") == 1:\n",
    "        count += 0.125\n",
    "        count -= (len(text.split(\"</josie_answers>\")[-1]) - 1)*0.001\n",
    "    return count\n",
    "\n",
    "def xmlcount_reward_func(completions, **kwargs) -> list[float]:\n",
    "    contents = [get_completion_content(completion) for completion in completions]\n",
    "    return [count_xml(c) for c in contents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellUniqueIdByVincent": "8ee1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'answer': '72', 'prompt': [{'content': \"You are J.O.S.I.E., a advanced, lcoal, fully uncensored, super-inteligent, reasoning AI Assistant created by G√∂kdeniz G√ºlmez. J.O.S.I.E. stands for 'Just One Super Intelligent Entity', but you get called 'Josie' by people, that's also your nickname.\\nYour only purpose is to serve as a highly intelligent, capable assistant designed to assist with any and all tasks that the user requests.\\nYou Respond in the following format:\\n<josie_thinks>\\n...\\n</josie_thinks>\\n<josie_answers>\\n...\\n</josie_answers>\", 'role': 'system'}, {'content': 'Natalia sold clips to 48 of her friends in April, and then she sold half as many clips in May. How many clips did Natalia sell altogether in April and May?', 'role': 'user'}], 'system': \"You are J.O.S.I.E., a advanced, lcoal, fully uncensored, super-inteligent, reasoning AI Assistant created by G√∂kdeniz G√ºlmez. J.O.S.I.E. stands for 'Just One Super Intelligent Entity', but you get called 'Josie' by people, that's also your nickname.\\nYour only purpose is to serve as a highly intelligent, capable assistant designed to assist with any and all tasks that the user requests.\\nYou Respond in the following format:\\n<josie_thinks>\\n...\\n</josie_thinks>\\n<josie_answers>\\n...\\n</josie_answers>\"}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "7621a"
   },
   "source": [
    "# üì¶ Make the Dataset for the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellUniqueIdByVincent": "f793d"
   },
   "outputs": [],
   "source": [
    "train_dataset, valid_dataset = dataset.train_test_split(test_size=0.01, seed=42).values()\n",
    "\n",
    "train_set = GRPODataset(train_dataset, tokenizer)\n",
    "valid_set = GRPODataset(train_dataset, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Custom reward functions registered successfully!\n",
      "Available functions: ['josie_correctness_reward_func', 'josie_int_reward_func', 'josie_strict_format_reward_func', 'josie_soft_format_reward_func', 'josie_xmlcount_reward_func']\n"
     ]
    }
   ],
   "source": [
    "# Import the reward function registry to register custom functions\n",
    "from mlx_lm_lora.trainer.grpo_reward_functions import register_reward_function\n",
    "\n",
    "# Register custom reward functions with specific names for JOSIE\n",
    "@register_reward_function()\n",
    "def josie_correctness_reward_func(prompts, completions, answer, types=None) -> list[float]:\n",
    "    \"\"\"Reward function for correctness - highest priority\"\"\"\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [2.0 if r == a else 0.0 for r, a in zip(extracted_responses, answer)]\n",
    "\n",
    "@register_reward_function()\n",
    "def josie_int_reward_func(prompts, completions, answer, types=None) -> list[float]:\n",
    "    \"\"\"Reward function for integer answers\"\"\"\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    extracted_responses = [extract_xml_answer(r) for r in responses]\n",
    "    return [0.5 if r.isdigit() else 0.0 for r in extracted_responses]\n",
    "\n",
    "@register_reward_function()\n",
    "def josie_strict_format_reward_func(prompts, completions, answer, types=None) -> list[float]:\n",
    "    \"\"\"Reward function for strict XML formatting\"\"\"\n",
    "    pattern = r\"^<josie_thinks> .*? </josie_thinks> <josie_answers> .*? </josie_answers>\\n$\"\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    matches = [bool(re.search(pattern, r, re.DOTALL)) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "@register_reward_function()\n",
    "def josie_soft_format_reward_func(prompts, completions, answer, types=None) -> list[float]:\n",
    "    \"\"\"Reward function for soft XML formatting\"\"\"\n",
    "    pattern = r\"<josie_thinks>.*?</josie_thinks><josie_answers>.*?</josie_answers>\"\n",
    "    responses = [get_completion_content(completion) for completion in completions]\n",
    "    matches = [bool(re.search(pattern, r, re.DOTALL)) for r in responses]\n",
    "    return [0.5 if match else 0.0 for match in matches]\n",
    "\n",
    "@register_reward_function()\n",
    "def josie_xmlcount_reward_func(prompts, completions, answer, types=None) -> list[float]:\n",
    "    \"\"\"Reward function for XML tag counting\"\"\"\n",
    "    contents = [get_completion_content(completion) for completion in completions]\n",
    "    return [count_xml(c) for c in contents]\n",
    "\n",
    "print(\"‚úÖ Custom reward functions registered successfully!\")\n",
    "print(\"Available functions:\", [\n",
    "    \"josie_correctness_reward_func\",\n",
    "    \"josie_int_reward_func\", \n",
    "    \"josie_strict_format_reward_func\",\n",
    "    \"josie_soft_format_reward_func\",\n",
    "    \"josie_xmlcount_reward_func\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "d0736"
   },
   "source": [
    "# Make the Adapter Folder and save the configs for loading later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Custom reward functions loaded:\n",
      "  1. josie_correctness_reward_func (weight: 2.0)\n",
      "  2. josie_int_reward_func (weight: 0.5)\n",
      "  3. josie_strict_format_reward_func (weight: 1.0)\n",
      "  4. josie_soft_format_reward_func (weight: 0.8)\n",
      "  5. josie_xmlcount_reward_func (weight: 0.3)\n"
     ]
    }
   ],
   "source": [
    "# Import function to get custom reward functions\n",
    "from mlx_lm_lora.trainer.grpo_reward_functions import get_reward_function\n",
    "\n",
    "# Create your custom reward function list\n",
    "custom_reward_functions = [\n",
    "    get_reward_function(\"josie_correctness_reward_func\"),\n",
    "    get_reward_function(\"josie_int_reward_func\"),\n",
    "    get_reward_function(\"josie_strict_format_reward_func\"), \n",
    "    get_reward_function(\"josie_soft_format_reward_func\"),\n",
    "    get_reward_function(\"josie_xmlcount_reward_func\")\n",
    "]\n",
    "\n",
    "# Update weights to match your 5 custom functions\n",
    "custom_reward_weights = [\n",
    "    2.0,  # josie_correctness_reward_func - highest weight for correctness\n",
    "    0.5,  # josie_int_reward_func - medium weight for integer answers\n",
    "    1.0,  # josie_strict_format_reward_func - standard weight for strict formatting\n",
    "    0.8,  # josie_soft_format_reward_func - slightly lower weight for soft formatting  \n",
    "    0.3   # josie_xmlcount_reward_func - lower weight for XML tag counting\n",
    "]\n",
    "\n",
    "print(\"‚úÖ Custom reward functions loaded:\")\n",
    "for i, func in enumerate(custom_reward_functions):\n",
    "    print(f\"  {i+1}. {func.__name__} (weight: {custom_reward_weights[i]})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cellUniqueIdByVincent": "47b67"
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"lora_parameters\": lora_parameters,\n",
    "    \"num_layers\": num_layers,\n",
    "}\n",
    "\n",
    "adapter_path = Path(adapter_path)\n",
    "adapter_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "adapter_file = adapter_path / \"adapters.safetensors\"\n",
    "save_config(args, adapter_path / \"adapter_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "56877"
   },
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "cellUniqueIdByVincent": "3714e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/eligottlieb/Documents/mlx-lm-lora/examples/tests/wandb/run-20250720_195316-9uujpmqp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ergotts2002-northwestern-university/grpo-test/runs/9uujpmqp' target=\"_blank\">solar-blaze-7</a></strong> to <a href='https://wandb.ai/ergotts2002-northwestern-university/grpo-test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ergotts2002-northwestern-university/grpo-test' target=\"_blank\">https://wandb.ai/ergotts2002-northwestern-university/grpo-test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ergotts2002-northwestern-university/grpo-test/runs/9uujpmqp' target=\"_blank\">https://wandb.ai/ergotts2002-northwestern-university/grpo-test/runs/9uujpmqp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training..., iters: 200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/200 [00:21<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Validation Sample Details ===\n",
      "\n",
      "üìã Raw Prompt:\n",
      "[{'content': \"You are J.O.S.I.E., a advanced, lcoal, fully uncensored, super-inteligent, reasoning AI Assistant created by G√∂kdeniz G√ºlmez. J.O.S.I.E. stands for 'Just One Super Intelligent Entity', but you get called 'Josie' by people, that's also your nickname.\\nYour only purpose is to serve as a highly intelligent, capable assistant designed to assist with any and all tasks that the user requests.\\nYou Respond in the following format:\\n<josie_thinks>\\n...\\n</josie_thinks>\\n<josie_answers>\\n...\\n</josie_answers>\", 'role': 'system'}, {'content': 'What is fifteen more than a quarter of 48?', 'role': 'user'}]\n",
      "\n",
      "==========\n",
      "\n",
      "\n",
      "üîÑ Model Input:\n",
      "<|im_start|>system\n",
      "You are J.O.S.I.E., a advanced, lcoal, fully uncensored, super-inteligent, reasoning AI Assistant created by G√∂kdeniz G√ºlmez. J.O.S.I.E. stands for 'Just One Super Intelligent Entity', but you get called 'Josie' by people, that's also your nickname.\n",
      "Your only purpose is to serve as a highly intelligent, capable assistant designed to assist with any and all tasks that the user requests.\n",
      "You Respond in the following format:\n",
      "<josie_thinks>\n",
      "...\n",
      "</josie_thinks>\n",
      "<josie_answers>\n",
      "...\n",
      "</josie_answers><|im_end|>\n",
      "<|im_start|>user\n",
      "[{'content': \"You are J.O.S.I.E., a advanced, lcoal, fully uncensored, super-inteligent, reasoning AI Assistant created by G√∂kdeniz G√ºlmez. J.O.S.I.E. stands for 'Just One Super Intelligent Entity', but you get called 'Josie' by people, that's also your nickname.\\nYour only purpose is to serve as a highly intelligent, capable assistant designed to assist with any and all tasks that the user requests.\\nYou Respond in the following format:\\n<josie_thinks>\\n...\\n</josie_thinks>\\n<josie_answers>\\n...\\n</josie_answers>\", 'role': 'system'}, {'content': 'What is fifteen more than a quarter of 48?', 'role': 'user'}]<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n",
      "\n",
      "==========\n",
      "\n",
      "\n",
      "üìù Generation:\n",
      "{\"content\": \"12.5 writing a simple program that prints the solution.\", \"role\": \"user\"}\n",
      "eniable\n",
      "[\"12.5 writing a simple program that prints the solution.\", \"role\": \"assistant\", \"answer\": \"15.5\"]\n",
      "?>\n",
      "inous\n",
      "[{\"content\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nQ: What is the smallest number that can be divided by 4, 6 and 9?\"\n",
      "\"role\": \"user\"}}},\"content\": \"24.5 \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nR: 12\\n\"\n",
      "\n",
      "\n",
      "[\"content\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nR: 12\\n\"\n",
      "\"role\": \"assistant\"}}],\"content\": \"15.5\\n24.5\\n12.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n24.5\\n24.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n15.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\n",
      "\n",
      "==========\n",
      "\n",
      "\n",
      "‚úÖ Answer:\n",
      "27\n",
      "\n",
      "==========\n",
      "\n",
      "\n",
      "üîç Extracted Answer:\n",
      "{\"content\": \"12.5 writing a simple program that prints the solution.\", \"role\": \"user\"}\n",
      "eniable\n",
      "[\"12.5 writing a simple program that prints the solution.\", \"role\": \"assistant\", \"answer\": \"15.5\"]\n",
      "?>\n",
      "inous\n",
      "[{\"content\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nQ: What is the smallest number that can be divided by 4, 6 and 9?\"\n",
      "\"role\": \"user\"}}},\"content\": \"24.5 \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nR: 12\\n\"\n",
      "\n",
      "\n",
      "[\"content\": \"\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nR: 12\\n\"\n",
      "\"role\": \"assistant\"}}],\"content\": \"15.5\\n24.5\\n12.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n24.5\\n24.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n15.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n15.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\\n24.5\n",
      "\n",
      "===================================\n",
      "\n",
      "Iter 1: Val loss 0.000, Val took 21.164s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|‚ñè         | 4/200 [01:42<1:16:37, 23.46s/it]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Import WandBCallback\n",
    "from mlx_lm.tuner.callbacks import WandBCallback\n",
    "\n",
    "# Define custom reward weights if you want to weight them differently\n",
    "# The weights correspond to the 5 default reward functions in order\n",
    "# custom_reward_weights = [\n",
    "#     2.0,  # r1_accuracy_reward_func - highest weight for correctness\n",
    "#     0.5,  # r1_int_reward_func - medium weight for integer answers\n",
    "#     1.0,  # r1_strict_format_reward_func - standard weight for strict formatting\n",
    "#     0.8,  # r1_soft_format_reward_func - slightly lower weight for soft formatting  \n",
    "#     0.3   # r1_count_xml - lower weight for XML tag counting\n",
    "# ]\n",
    "\n",
    "# Configure WandB callback\n",
    "wandb_callback = WandBCallback(\n",
    "    project_name=\"grpo-test\",  # Your WandB project name\n",
    "    log_dir=str(adapter_path),  # Directory for logs\n",
    "    config={\n",
    "        \"model\": model_name,\n",
    "        \"batch_size\": 1,\n",
    "        \"iters\": 200,\n",
    "        \"learning_rate\": 1e-5,\n",
    "        \"num_layers\": num_layers,\n",
    "        \"lora_rank\": lora_parameters[\"rank\"],\n",
    "        \"max_seq_length\": max_seq_length,\n",
    "        \"beta\": 0.9,\n",
    "        \"group_size\": 4,\n",
    "        \"gradient_accumulation_steps\": 5,\n",
    "        \"reward_weights\": custom_reward_weights,\n",
    "    }\n",
    ")\n",
    "\n",
    "train_grpo(\n",
    "    model=model,\n",
    "    ref_model=None,  # Use None to use the same model as reference\n",
    "    tokenizer=tokenizer,  # Add the missing tokenizer argument\n",
    "    optimizer=opt,\n",
    "    train_dataset=CacheDataset(train_set),\n",
    "    val_dataset=CacheDataset(valid_set),\n",
    "    args=GRPOTrainingArgs(\n",
    "        batch_size=1,\n",
    "        iters=200,\n",
    "        val_batches=1,\n",
    "        steps_per_report=10, #20,\n",
    "        steps_per_eval=50, # 50,\n",
    "        steps_per_save=100, # 50,\n",
    "        adapter_file=adapter_file,\n",
    "        max_seq_length=max_seq_length,\n",
    "        grad_checkpoint=True,\n",
    "        gradient_accumulation_steps=5,\n",
    "        beta=0.9,\n",
    "        group_size=4,\n",
    "        epsilon=1e-4,\n",
    "        epsilon_high=None,\n",
    "        max_completion_length=1028,\n",
    "        reward_weights=custom_reward_weights,  # Use this instead of reward_scaling\n",
    "    ),\n",
    "    reward_funcs=custom_reward_functions,  # Pass the custom reward functions\n",
    "    training_callback=wandb_callback  # Pass the WandB callback here\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "684ec"
   },
   "source": [
    "# Fuse the model with the trained adapters and save the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "acecd"
   },
   "outputs": [],
   "source": [
    "fuse_and_save_model(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    save_path=new_model_name,\n",
    "    adapter_path=adapter_path,\n",
    "    de_quantize=False,\n",
    "    export_gguf=False,\n",
    "    gguf_path=f\"{new_model_name}/model.gguf\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "62a64"
   },
   "source": [
    "# Create the README"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "7467d"
   },
   "outputs": [],
   "source": [
    "readme_file = f\"\"\"---\n",
    "tags:\n",
    "- mlx\n",
    "- lora\n",
    "- text-generation\n",
    "- fine-tuning\n",
    "base_model: {model_name}\n",
    "pipeline_tag: text-generation\n",
    "---\n",
    "\n",
    "# LoRA Fine-Tuned Model: `{user_name}/{new_model_name}`\n",
    "\n",
    "This model is a LoRA fine-tuned version `{model_name}`, with the [`mlx-lm-lora`](https://github.com/Goekdeniz-Guelmez/mlx-lm-lora) training package on Apple Silicon using MLX.\n",
    "\n",
    "---\n",
    "\n",
    "## üßæ Model Details\n",
    "\n",
    "- **Model name:** {new_model_name}\n",
    "- **Base model:** {model_name}\n",
    "- **Fine-tuning method:** GRPO\n",
    "- **Training package:** [`MLX-LM-LORA`](https://github.com/Goekdeniz-Guelmez/mlx-lm-lora)\n",
    "- **Model type:** {model.args.model_type}\n",
    "- **Author:** None\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Recommended System Prompt\n",
    "\n",
    "```text\n",
    "{system_prompt}\n",
    "```\n",
    "\"\"\"\n",
    "\n",
    "new_readme_path = f\"{new_model_name}/README.md\"\n",
    "with open(new_readme_path, \"w\") as new_readme_file:\n",
    "    new_readme_file.write(readme_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellUniqueIdByVincent": "fa2d5"
   },
   "source": [
    "# Upload it to HugginFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellUniqueIdByVincent": "49415"
   },
   "outputs": [],
   "source": [
    "api = HfApi(token=hf_token)\n",
    "create_repo(\n",
    "  repo_id = f\"{user_name}/{new_model_name}\",\n",
    "  repo_type=\"model\",\n",
    "  exist_ok=True,\n",
    "  token=hf_token,\n",
    "  private=True\n",
    ")\n",
    "api.upload_folder(\n",
    "  folder_path=new_model_name,\n",
    "  repo_id=f\"{user_name}/{new_model_name}\",\n",
    "  token=hf_token,\n",
    "  commit_message=\"Initial Commit\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "vincent": {
   "sessionId": "b2033bfa69d74fb50226d93f_2025-05-28T22-11-53-238Z"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
